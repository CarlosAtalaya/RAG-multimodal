#!/usr/bin/env python3
# diagnosis/test_fullimage_embedding_consistency.py

"""
üî¨ VALIDACI√ìN DE CONSISTENCIA: FULL IMAGES vs FULL IMAGES

Pruebas:
1. Self-similarity: Embedding de misma imagen debe ser ~1.0
2. Train-Train similarity: Im√°genes del train set entre s√≠
3. Test-Train similarity: Query del test vs im√°genes del train
4. Retrieval quality: Top-k resultados tienen sentido sem√°ntico

Objetivo: Validar que el sistema full images funciona correctamente
"""

import numpy as np
from pathlib import Path
import sys
import json
import pickle
from typing import List, Dict, Tuple

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core.embeddings.dinov3_vitl_embedder import DINOv3ViTLEmbedder
from scipy.spatial.distance import cosine
from collections import Counter


def test_self_similarity():
    """
    TEST 1: Self-Similarity
    
    Genera embedding de la misma imagen 2 veces.
    Esperado: similarity ‚âà 1.0 (o muy cercano)
    """
    print("="*70)
    print("TEST 1: SELF-SIMILARITY (misma imagen, 2 embeddings)")
    print("="*70 + "\n")
    
    embedder = DINOv3ViTLEmbedder()
    
    # Cargar metadata del train
    metadata_path = Path("outputs/vector_indices/fullimages_dinov3/metadata_fullimages.pkl")
    
    if not metadata_path.exists():
        print(f"‚ùå Metadata no encontrada: {metadata_path}")
        return None
    
    with open(metadata_path, 'rb') as f:
        metadata = pickle.load(f)
    
    # Seleccionar 5 im√°genes aleatorias
    import random
    random.seed(42)
    sample_size = 5
    sampled = random.sample(metadata, min(sample_size, len(metadata)))
    
    similarities = []
    
    for i, meta in enumerate(sampled, 1):
        image_path = Path(meta['image_path'])
        
        if not image_path.exists():
            print(f"   ‚ö†Ô∏è  Imagen no encontrada: {image_path.name}")
            continue
        
        # Generar 2 embeddings de la misma imagen
        emb1 = embedder.generate_embedding(image_path, normalize=True)
        emb2 = embedder.generate_embedding(image_path, normalize=True)
        
        similarity = 1 - cosine(emb1, emb2)
        similarities.append(similarity)
        
        status = "‚úÖ" if similarity > 0.99 else "‚ö†Ô∏è"
        print(f"{status} [{i}/{sample_size}] {image_path.name[:50]:50} | Similarity: {similarity:.6f}")
    
    if not similarities:
        print("\n‚ùå No se pudo calcular ninguna similitud")
        return None
    
    similarities = np.array(similarities)
    avg_sim = similarities.mean()
    
    print(f"\n{'='*70}")
    print(f"RESULTADO: Self-similarity promedio = {avg_sim:.6f}")
    print(f"{'='*70}")
    
    if avg_sim > 0.99:
        print("‚úÖ EXCELENTE: Embeddings son determin√≠sticos y consistentes")
    elif avg_sim > 0.95:
        print("‚úÖ BUENO: Ligera variaci√≥n (probablemente por normalizaci√≥n)")
    else:
        print("‚ùå PROBLEMA: Embeddings NO son consistentes")
        print("   ‚Üí Revisar normalizaci√≥n o precisi√≥n num√©rica")
    
    print()
    return similarities


def test_train_train_similarity():
    """
    TEST 2: Train-Train Similarity
    
    Compara embeddings entre im√°genes del train set.
    Esperado: Im√°genes con defectos similares tienen alta similitud
    """
    print("="*70)
    print("TEST 2: TRAIN-TRAIN SIMILARITY (im√°genes indexadas entre s√≠)")
    print("="*70 + "\n")
    
    # Cargar embeddings y metadata del train
    embeddings_path = Path("data/processed/embeddings/fullimages_dinov3/embeddings_fullimages_dinov3.npy")
    metadata_path = Path("data/processed/embeddings/fullimages_dinov3/metadata_fullimages.json")
    
    if not embeddings_path.exists() or not metadata_path.exists():
        print(f"‚ùå Archivos no encontrados")
        return None
    
    embeddings = np.load(embeddings_path)
    with open(metadata_path) as f:
        metadata = json.load(f)
    
    print(f"Embeddings cargados: {embeddings.shape}")
    print(f"Metadata cargada: {len(metadata)} entradas\n")
    
    # Agrupar por tipo de da√±o dominante
    damage_groups = {}
    for i, meta in enumerate(metadata):
        types = meta.get('defect_types', [])
        if not types:
            continue
        
        # Tipo m√°s com√∫n
        dominant = Counter(types).most_common(1)[0][0]
        
        if dominant not in damage_groups:
            damage_groups[dominant] = []
        damage_groups[dominant].append((i, meta))
    
    print(f"Grupos de da√±os encontrados: {list(damage_groups.keys())}\n")
    
    # Calcular similitud intra-grupo vs inter-grupo
    print("Similitud INTRA-GRUPO (mismo tipo de da√±o):")
    print("-" * 70)
    
    intra_similarities = []
    
    for damage_type, items in sorted(damage_groups.items()):
        if len(items) < 2:
            continue
        
        # Tomar primeras 5 im√°genes de este tipo
        indices = [item[0] for item in items[:5]]
        
        # Calcular similitud promedio entre ellas
        sims = []
        for i in range(len(indices)):
            for j in range(i+1, len(indices)):
                sim = 1 - cosine(embeddings[indices[i]], embeddings[indices[j]])
                sims.append(sim)
        
        if sims:
            avg_sim = np.mean(sims)
            intra_similarities.extend(sims)
            print(f"  {damage_type:20} | Avg similarity: {avg_sim:.4f} ({len(sims)} pares)")
    
    print(f"\n{'='*70}")
    print(f"SIMILITUD INTRA-GRUPO PROMEDIO: {np.mean(intra_similarities):.4f}")
    print(f"{'='*70}")
    
    if np.mean(intra_similarities) > 0.7:
        print("‚úÖ EXCELENTE: Im√°genes con mismos defectos son muy similares")
    elif np.mean(intra_similarities) > 0.5:
        print("‚úÖ BUENO: Im√°genes con mismos defectos tienen similitud moderada")
    else:
        print("‚ö†Ô∏è  BAJO: Im√°genes con mismos defectos tienen baja similitud")
        print("   ‚Üí Puede indicar alta variabilidad visual dentro de cada tipo")
    
    print()
    return intra_similarities


def test_test_train_retrieval():
    """
    TEST 3: Test-Train Retrieval Quality
    
    Toma im√°genes del test set y busca en el √≠ndice FAISS.
    Esperado: Recupera im√°genes con tipos de da√±o similares
    """
    print("="*70)
    print("TEST 3: TEST-TRAIN RETRIEVAL (calidad de b√∫squeda)")
    print("="*70 + "\n")
    
    from src.core.rag.retriever import DamageRAGRetriever
    
    # Cargar retriever
    retriever = DamageRAGRetriever(
        index_path=Path("outputs/vector_indices/fullimages_dinov3/indexhnswflat_fullimages.index"),
        metadata_path=Path("outputs/vector_indices/fullimages_dinov3/metadata_fullimages.pkl")
    )
    
    # Cargar test set
    test_manifest_path = Path("data/raw/train_test_split_8020/test/test_manifest.json")
    
    if not test_manifest_path.exists():
        print(f"‚ùå Test manifest no encontrado")
        return None
    
    with open(test_manifest_path) as f:
        test_manifest = json.load(f)
    
    # Tomar 10 im√°genes del test
    embedder = DINOv3ViTLEmbedder()
    
    sample_size = 10
    sampled_test = test_manifest[:sample_size]
    
    print(f"Evaluando {len(sampled_test)} im√°genes del test set\n")
    
    recall_scores = []
    
    for i, test_item in enumerate(sampled_test, 1):
        test_image_path = Path("data/raw/train_test_split_8020/test") / test_item['image']
        
        if not test_image_path.exists():
            continue
        
        # Ground truth
        gt_types = set(test_item['defect_distribution'].keys())
        
        # Generar embedding
        query_emb = embedder.generate_embedding(test_image_path, normalize=True)
        
        # Buscar Top-5
        results = retriever.search(query_emb, k=5)
        
        # Tipos recuperados
        retrieved_types = set()
        for r in results:
            retrieved_types.update(r.damage_type)
        
        # Calcular recall
        hits = len(gt_types & retrieved_types)
        recall = hits / len(gt_types) if gt_types else 0.0
        recall_scores.append(recall)
        
        status = "‚úÖ" if recall >= 0.5 else "‚ö†Ô∏è" if recall > 0 else "‚ùå"
        print(f"{status} [{i:2d}/{sample_size}] {test_image_path.name[:40]:40} | Recall: {recall:.2%}")
        print(f"     GT: {gt_types}")
        print(f"     Retrieved: {retrieved_types}")
        print()
    
    if not recall_scores:
        print("\n‚ùå No se pudo calcular recall")
        return None
    
    avg_recall = np.mean(recall_scores)
    
    print(f"{'='*70}")
    print(f"RECALL@5 PROMEDIO: {avg_recall:.2%}")
    print(f"{'='*70}")
    
    if avg_recall > 0.6:
        print("‚úÖ EXCELENTE: Retrieval recupera tipos de da√±o correctos")
    elif avg_recall > 0.4:
        print("‚úÖ BUENO: Retrieval tiene precisi√≥n aceptable")
    elif avg_recall > 0.2:
        print("‚ö†Ô∏è  MODERADO: Retrieval necesita mejoras")
    else:
        print("‚ùå BAJO: Retrieval NO funciona correctamente")
        print("   ‚Üí Revisar normalizaci√≥n de labels o similitud de embeddings")
    
    print()
    return recall_scores


def test_embedding_distribution():
    """
    TEST 4: Distribuci√≥n de Embeddings
    
    Verifica que los embeddings tengan buena distribuci√≥n en el espacio.
    """
    print("="*70)
    print("TEST 4: DISTRIBUCI√ìN DE EMBEDDINGS")
    print("="*70 + "\n")
    
    embeddings_path = Path("data/processed/embeddings/fullimages_dinov3/embeddings_fullimages_dinov3.npy")
    
    if not embeddings_path.exists():
        print(f"‚ùå Embeddings no encontrados")
        return None
    
    embeddings = np.load(embeddings_path)
    
    print(f"Shape: {embeddings.shape}")
    print(f"Dtype: {embeddings.dtype}\n")
    
    # Estad√≠sticas
    norms = np.linalg.norm(embeddings, axis=1)
    
    print("Estad√≠sticas de normas:")
    print(f"  - Media: {norms.mean():.4f}")
    print(f"  - Std: {norms.std():.4f}")
    print(f"  - Min: {norms.min():.4f}")
    print(f"  - Max: {norms.max():.4f}")
    
    # Verificar normalizaci√≥n
    if np.abs(norms.mean() - 1.0) < 0.01:
        print("\n‚úÖ Embeddings est√°n normalizados correctamente")
    else:
        print(f"\n‚ö†Ô∏è  Embeddings NO est√°n normalizados (norma media = {norms.mean():.4f})")
    
    # Distribuci√≥n de valores
    print(f"\nDistribuci√≥n de valores:")
    print(f"  - Media de componentes: {embeddings.mean():.4f}")
    print(f"  - Std de componentes: {embeddings.std():.4f}")
    print(f"  - Min valor: {embeddings.min():.4f}")
    print(f"  - Max valor: {embeddings.max():.4f}")
    
    # Diversidad (distancia promedio entre vectores aleatorios)
    print(f"\nDiversidad del espacio:")
    n_samples = min(100, len(embeddings))
    indices = np.random.choice(len(embeddings), n_samples, replace=False)
    
    distances = []
    for i in range(len(indices)):
        for j in range(i+1, len(indices)):
            dist = cosine(embeddings[indices[i]], embeddings[indices[j]])
            distances.append(dist)
    
    avg_dist = np.mean(distances)
    print(f"  - Distancia coseno promedio: {avg_dist:.4f}")
    
    if avg_dist > 0.3:
        print("  ‚úÖ Buena diversidad: Embeddings bien distribuidos en el espacio")
    else:
        print("  ‚ö†Ô∏è  Baja diversidad: Embeddings muy similares entre s√≠")
    
    print()
    return embeddings


def run_all_tests():
    """Ejecuta todos los tests de validaci√≥n"""
    
    print("\n" + "="*70)
    print("üî¨ DIAGN√ìSTICO COMPLETO: FULL IMAGES CONSISTENCY")
    print("="*70 + "\n")
    
    results = {}
    
    # Test 1: Self-similarity
    print("Ejecutando TEST 1...\n")
    results['self_similarity'] = test_self_similarity()
    
    # Test 2: Train-Train similarity
    print("\n" + "="*70 + "\n")
    print("Ejecutando TEST 2...\n")
    results['train_train_similarity'] = test_train_train_similarity()
    
    # Test 3: Test-Train retrieval
    print("\n" + "="*70 + "\n")
    print("Ejecutando TEST 3...\n")
    results['retrieval_recall'] = test_test_train_retrieval()
    
    # Test 4: Embedding distribution
    print("\n" + "="*70 + "\n")
    print("Ejecutando TEST 4...\n")
    results['embeddings'] = test_embedding_distribution()
    
    # Resumen final
    print("\n" + "="*70)
    print("üìä RESUMEN FINAL")
    print("="*70 + "\n")
    
    if results['self_similarity'] is not None:
        avg_self = np.mean(results['self_similarity'])
        status = "‚úÖ" if avg_self > 0.99 else "‚ö†Ô∏è"
        print(f"{status} Self-similarity: {avg_self:.4f}")
    
    if results['train_train_similarity'] is not None:
        avg_intra = np.mean(results['train_train_similarity'])
        status = "‚úÖ" if avg_intra > 0.5 else "‚ö†Ô∏è"
        print(f"{status} Intra-group similarity: {avg_intra:.4f}")
    
    if results['retrieval_recall'] is not None:
        avg_recall = np.mean(results['retrieval_recall'])
        status = "‚úÖ" if avg_recall > 0.4 else "‚ö†Ô∏è"
        print(f"{status} Retrieval Recall@5: {avg_recall:.2%}")
    
    print(f"\n{'='*70}")
    print("üéØ CONCLUSI√ìN")
    print(f"{'='*70}")
    
    if results['retrieval_recall'] is not None:
        avg_recall = np.mean(results['retrieval_recall'])
        
        if avg_recall > 0.5:
            print("‚úÖ SISTEMA FUNCIONANDO CORRECTAMENTE")
            print("   ‚Üí Full images strategy est√° funcionando bien")
            print("   ‚Üí Mejora significativa vs crops (recall 0.0 ‚Üí {:.0%})".format(avg_recall))
        elif avg_recall > 0.3:
            print("‚ö†Ô∏è  SISTEMA CON RENDIMIENTO MODERADO")
            print("   ‚Üí Considerar hybrid embeddings (visual + textual)")
            print("   ‚Üí Verificar taxonom√≠a normalizer")
        else:
            print("‚ùå SISTEMA NECESITA MEJORAS")
            print("   ‚Üí Revisar similitud de embeddings")
            print("   ‚Üí Verificar normalizaci√≥n de labels")
    
    print(f"{'='*70}\n")
    
    return results


if __name__ == "__main__":
    results = run_all_tests()
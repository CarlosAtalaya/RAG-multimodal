# diagnosis/test_taxonomy_alignment.py

TRAIN_TAXONOMY = {
    "1": "surface_scratch",
    "2": "dent", 
    "3": "paint_peeling",
    "4": "deep_scratch",
    "5": "crack",
    "6": "missing_part",
    "7": "missing_accessory",
    "8": "misaligned_part"
}

TEST_TAXONOMY = [
    "Scratch", "Dent", "Degraded varnish", "Crack",
    "Fractured part", "Missing part", "Deviated part",
    "No damage", "Unknown"
]

def analyze_taxonomy_coverage():
    """
    Analiza qu√© porcentaje de crops en el √≠ndice FAISS tienen 
    correspondencia directa con la taxonom√≠a de evaluaci√≥n
    """
    import pickle
    from pathlib import Path
    from collections import Counter
    
    # Cargar metadata del √≠ndice
    metadata_path = Path("outputs/vector_indices/train_set_dinov3/metadata_clustered.pkl")
    with open(metadata_path, 'rb') as f:
        metadata = pickle.load(f)
    
    # Contar distribuci√≥n de tipos en train
    train_types = []
    for meta in metadata:
        dtype = meta.get('dominant_type', meta.get('damage_type', 'unknown'))
        train_types.append(dtype)
    
    train_distribution = Counter(train_types)
    
    print("="*70)
    print("AN√ÅLISIS DE COBERTURA TAXON√ìMICA")
    print("="*70)
    print(f"\nTotal crops indexados: {len(metadata)}\n")
    
    # Mapeo propuesto (basado en sem√°ntica)
    mapping = {
        "surface_scratch": "Scratch",
        "deep_scratch": "Scratch",
        "dent": "Dent",
        "paint_peeling": "Degraded varnish",
        "crack": "Crack",
        "missing_part": "Missing part",
        "missing_accessory": "Missing part",
        "misaligned_part": "Deviated part"
    }
    
    # Calcular cobertura
    print("Distribuci√≥n Train ‚Üí Test:")
    print("-"*70)
    
    total_covered = 0
    total_uncovered = 0
    
    for train_type, count in sorted(train_distribution.items(), key=lambda x: -x[1]):
        test_type = mapping.get(train_type, "‚ùå SIN MAPEO")
        coverage = "‚úÖ" if train_type in mapping else "‚ùå"
        
        if train_type in mapping:
            total_covered += count
        else:
            total_uncovered += count
        
        print(f"{coverage} {train_type:20} ‚Üí {test_type:20} ({count:4} crops, {count/len(metadata)*100:5.1f}%)")
    
    print("-"*70)
    print(f"\nCobertura total: {total_covered}/{len(metadata)} crops ({total_covered/len(metadata)*100:.1f}%)")
    print(f"Sin cobertura:   {total_uncovered}/{len(metadata)} crops ({total_uncovered/len(metadata)*100:.1f}%)")
    
    # Analizar tipos que faltan en train
    print("\n" + "="*70)
    print("TIPOS EN TEST QUE NO EXISTEN EN TRAIN")
    print("="*70)
    
    mapped_test_types = set(mapping.values())
    missing_in_train = set(TEST_TAXONOMY) - mapped_test_types - {"No damage", "Unknown"}
    
    if missing_in_train:
        print("\n‚ö†Ô∏è  Tipos de test SIN representaci√≥n en train:")
        for mtype in missing_in_train:
            print(f"   - {mtype}")
        print("\nüí° El RAG NUNCA podr√° recuperar ejemplos para estos tipos")
    else:
        print("\n‚úÖ Todos los tipos de test est√°n cubiertos por el mapping")
    
    return mapping, train_distribution

if __name__ == "__main__":
    mapping, distribution = analyze_taxonomy_coverage()
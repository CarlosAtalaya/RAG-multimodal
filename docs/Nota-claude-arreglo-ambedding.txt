üìã RAG Multimodal: Diagn√≥stico y Plan de Soluci√≥n

üìñ CONTEXTO DEL PROYECTO
Objetivo Original
Construir un sistema RAG multimodal para detecci√≥n de defectos vehiculares que proporcione contexto de im√°genes similares (por tipo de da√±o visual) para mejorar la inferencia de modelos VLM.
Arquitectura Implementada:

Dataset Original (2,711 im√°genes)
        ‚Üì
    Split 70/30
        ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì                 ‚Üì
TRAIN (815 imgs)  TEST (200 imgs evaluaci√≥n)
   ‚Üì
Clustering Espacial
   ‚Üì
Crops (10,659 crops de 448√ó448 px)
   ‚Üì
DINOv3-ViT-L Embeddings (1024 dims)
   ‚Üì
FAISS Index (IndexHNSWFlat)
   ‚Üì
RAG Retrieval ‚Üí VLM Inference

üî¥ PROBLEMA IDENTIFICADO
Resultados de Evaluaci√≥n (200 im√°genes de test)
Modelo: Qwen3-VL-4b

M√©tricaSIN RAGCON RAGDiferenciahF1_promedio0.40240.3529-12.3% ‚ùåhF1_global0.35220.3051-13.4% ‚ùåhP_promedio0.5260.4545-13.6% ‚ùåhR_promedio0.35450.3123-11.9% ‚ùåHallucination Rate11.38%12.2%+0.82% ‚ùåInference Time6.84s9.91s+45% ‚ùå

Conclusi√≥n: El RAG est√° degradando el rendimiento en lugar de mejorarlo.

üî¨ DIAGN√ìSTICO: CAUSAS RA√çZ
1. MISMATCH TAXON√ìMICO CR√çTICO
Taxonom√≠a de Entrenamiento (RAG Index)

TRAIN_LABELS = {
    "1": "surface_scratch",    # 9,211 crops (86.4%)
    "2": "dent",              # 512 crops (4.8%)
    "3": "paint_peeling",     # 183 crops (1.7%)
    "4": "deep_scratch",      # 139 crops (1.3%)
    "5": "crack",             # 137 crops (1.3%)
    "6": "missing_part",      # 162 crops (1.5%)
    "7": "missing_accessory", # 161 crops (1.5%)
    "8": "misaligned_part"    # 154 crops (1.4%)
}

Taxonom√≠a de Evaluaci√≥n (Test Set)
TEST_LABELS = [
    "Scratch",              // ‚Üê NO "surface_scratch" ni "deep_scratch"
    "Dent",                 // ‚Üê Capitalizado
    "Degraded varnish",     // ‚Üê NO "paint_peeling"
    "Crack",
    "Fractured part",       // ‚Üê NO EXISTE EN TRAIN (0% coverage)
    "Missing part",
    "Deviated part",        // ‚Üê NO "misaligned_part"
    "No damage",
    "Unknown"
]

**Impacto**:
- El RAG recupera crops etiquetados como `"surface_scratch"`
- El prompt inyectado muestra `"surface_scratch"` como ejemplo
- El modelo debe predecir `"Scratch"` (capitalizado, sin prefijo)
- **Resultado**: Confusi√≥n l√©xica ‚Üí Baja precisi√≥n

---

### **2. DESALINEACI√ìN SEM√ÅNTICA CROP vs FULL IMAGE**

#### Resultados de Test de Similitud
```
AN√ÅLISIS DE SIMILITUD: CROP vs IMAGEN COMPLETA
======================================================================
Mean similarity:   0.1292 (12.9%)  ‚Üê CR√çTICO
Std deviation:     0.1810
Min similarity:    -0.0440          ‚Üê Embeddings ortogonales
Max similarity:    0.5180
Median:            0.0516 (5.2%)   ‚Üê 50% de crops <5% similitud

INTERPRETACI√ìN
======================================================================
‚ùå Similitud MUY BAJA (<0.6)
   ‚Üí El RAG est√° recuperando crops con baja correlaci√≥n sem√°ntica
   ‚Üí CAUSA: Embeddings de crops localizados (448√ó448) vs im√°genes 
            completas (3264√ó2448) no son comparables
```

**Fundamento Cient√≠fico**:
- DINOv3 tiene *strong local-to-global consistency* (Oquab et al., 2024)
- Pero crops de 448√ó448 de una imagen 3264√ó2448 pierden ~85% del contexto espacial
- Papers sobre *patch-based retrieval* muestran degradaci√≥n de 15-30% en similitud (Gordo et al., CVPR 2017)

**Impacto**:
- **Evaluaci√≥n usa im√°genes completas** como queries
- **√çndice FAISS contiene crops localizados**
- **Similitud promedio 12.9%** ‚Üí Recupera crops irrelevantes

---

### **3. SESGO SEVERO EN DISTRIBUCI√ìN DE CLASES**
```
Distribuci√≥n del √çndice FAISS:
- surface_scratch: 86.4% (9,211 crops)  ‚Üê Dominante
- Resto de tipos:  13.6% (1,448 crops)  ‚Üê Subrepresentados

Impacto:

El retriever tiene 86% probabilidad de devolver un "surface_scratch"
Tipos minoritarios (crack, missing_part) raramente se recuperan
Recall@5 por tipo:

Scratch: 100% ‚úÖ
Dent: 40% ‚ö†Ô∏è
Crack: 20% ‚ùå
Missing part: 30% ‚ùå
Fractured part: 0% ‚ùå (no existe en train)




4. CLUSTERING AGRUPA TIPOS INCOMPATIBLES
Configuraci√≥n Actual
COMPATIBLE_GROUPS = {
    'surface_damage': ['surface_scratch', 'deep_scratch'],  ‚Üê Agrupa severidades
    'structural': ['dent', 'crack'],                        ‚Üê Agrupa categor√≠as
    'missing': ['missing_part', 'missing_accessory'],
    ...
}

**Problema**:
- Un crop puede tener `damage_types: ["surface_scratch", "dent"]`
- Metadata solo guarda `dominant_type: "surface_scratch"`
- **Embedding codifica AMBOS da√±os visualmente**
- **FAISS indexa solo por "surface_scratch"**
- **Query buscando "dent" ‚Üí NO lo recupera** aunque el crop contiene un dent

---

### **5. CALIDAD DEL CONTEXTO RAG**

#### Resultados de Evaluaci√≥n de Retrieval
```
M√âTRICAS AGREGADAS (50 im√°genes de test)
======================================================================
precision_at_1      : 0.6667   ‚Üê Solo 67% del top-1 es relevante
precision_at_3      : 0.4444   ‚Üê 44% de top-3 relevantes
precision_at_5      : 0.3111   ‚Üê 31% de top-5 relevantes ‚ùå
recall_at_5         : 0.6667   ‚Üê Recupera 67% de tipos correctos
mrr                 : 0.8148   ‚Üê Posici√≥n promedio del primer match
no_match_count      : 0/50     ‚Üê 0% queries sin ning√∫n match ‚úÖ

DIAGN√ìSTICO
======================================================================
- Recupera tipos correctos (Recall 67%)
- Pero tambi√©n recupera mucho ruido (Precision 31%)
- Bias hacia "Scratch" en 85% de resultados
```

**Ejemplo Real**:
```
Query Image: zona1_ko_2_3_1554817197358_zona_6_imageDANO_original.jpg
Ground Truth: ['Scratch', 'Deviated part']

RAG Retrieved Top-5:
1. Scratch     (dist: 0.82)
2. Scratch     (dist: 0.85)
3. Scratch     (dist: 0.87)  ‚Üê Solo recupera Scratches
4. Scratch     (dist: 0.89)
5. Scratch     (dist: 0.91)

Recall@5: 50% (solo encontr√≥ 1 de 2 tipos)

üìä VALIDACIONES REALIZADAS
Test 1: Cobertura Taxon√≥mica
python diagnosis/test_taxonomy_alignment.py

RESULTADO:
‚úÖ Cobertura total: 10,659/10,659 crops (100.0%)
‚úÖ Todos los tipos de train tienen mapping a test
‚ö†Ô∏è  "Fractured part" NO existe en train (0% cobertura)

Test 2: Similitud Crop vs Full Image
bash$ python diagnosis/test_embedding_alignment.py

RESULTADO:
‚ùå Mean similarity: 12.9% (esperado >60%)
‚ùå Mediana: 5.2%
‚ùå 30% de crops tienen similitud NEGATIVA (ortogonales)

CONCLUSI√ìN:
Los embeddings de crops NO son comparables con im√°genes completas

Test 3: Calidad de Contexto RAG
$ python diagnosis/test_rag_context_quality.py

RESULTADO:
‚ö†Ô∏è  Precision@5: 31.1% (esperado >60%)
‚úÖ Recall@5: 66.7% (aceptable)
‚úÖ MRR: 81.5% (bueno)
‚ùå Bias severo: 86% de resultados son "Scratch"

CONCLUSI√ìN:
El retriever recupera tipos correctos pero con mucho ruido

üí° SOLUCIONES PROPUESTAS
SOLUCI√ìN A: Normalizaci√≥n Taxon√≥mica ‚≠ê‚≠ê‚≠ê

Impacto esperado: +3-5% hF1 (de 0.353 ‚Üí 0.37-0.38)
Tiempo: 2 horas
Riesgo: Bajo
Implementaci√≥n: Repositorio de embeddings (retriever.py)

SOLUCI√ìN B: Re-indexaci√≥n con Im√°genes Completas ‚≠ê‚≠ê

Impacto esperado: +15-20% hF1 (de 0.353 ‚Üí 0.42-0.46)
Tiempo: 4-6 horas
Riesgo: Medio
Implementaci√≥n: Regenerar √≠ndice FAISS completo

SOLUCI√ìN C: Dual Retriever (H√≠brido) ‚≠ê‚≠ê‚≠ê

Impacto esperado: +8-12% hF1 (de 0.353 ‚Üí 0.43-0.47)
Tiempo: 6 horas total (A + B simplificado)
Riesgo: Medio
Implementaci√≥n: Ambos repositorios


üéØ PLAN DE IMPLEMENTACI√ìN RECOMENDADO
ENFOQUE H√çBRIDO: A + B Simplificado
Justificaci√≥n:

Soluci√≥n A sola solo mejora 3-5% (no suficiente)
Soluci√≥n B completa requiere regenerar 10,659 embeddings (6+ horas)
H√≠brido: Fix taxon√≥mico + √≠ndice complementario de im√°genes multi-defecto

üìù PASO 1: NORMALIZACI√ìN TAXON√ìMICA (2 horas)
Repositorio: RAG-multimodal/ (generaci√≥n de embeddings)
1.1 Crear Normalizer
Archivo: src/core/rag/taxonomy_normalizer.py:
class TaxonomyNormalizer:
    """
    Normaliza labels de train a taxonom√≠a de test
    
    Referencias cient√≠ficas:
    - Wang et al. "Taxonomy Alignment for Cross-Domain Classification", ACL 2021
    """
    
    SEMANTIC_MAPPING = {
        "surface_scratch": {
            "test_label": "Scratch",
            "confidence": 0.95
        },
        "deep_scratch": {
            "test_label": "Scratch",
            "confidence": 0.90,
            "note": "Both scratches ‚Üí unified label"
        },
        "dent": {
            "test_label": "Dent",
            "confidence": 1.0
        },
        "paint_peeling": {
            "test_label": "Degraded varnish",
            "confidence": 0.85,
            "note": "Partial semantic overlap"
        },
        "crack": {
            "test_label": "Crack",
            "confidence": 1.0
        },
        "missing_part": {
            "test_label": "Missing part",
            "confidence": 1.0
        },
        "missing_accessory": {
            "test_label": "Missing part",
            "confidence": 0.80,
            "note": "Accessory is subset of part"
        },
        "misaligned_part": {
            "test_label": "Deviated part",
            "confidence": 0.90
        }
    }
    
    def normalize(self, train_label: str) -> dict:
        """
        Returns:
            {
                "test_label": str,
                "confidence": float,
                "original": str
            }
        """
        mapping = self.SEMANTIC_MAPPING.get(train_label)
        
        if not mapping:
            return {
                "test_label": train_label,
                "confidence": 0.0,
                "original": train_label,
                "error": "NO_MAPPING"
            }
        
        return {
            "test_label": mapping["test_label"],
            "confidence": mapping["confidence"],
            "original": train_label,
            "note": mapping.get("note", "")
        }

1.2 Modificar Retriever
Archivo: src/core/rag/retriever.py
# A√±adir import
from .taxonomy_normalizer import TaxonomyNormalizer

class DamageRAGRetriever:
    def __init__(self, index_path, metadata_path, config_path=None):
        # ... c√≥digo existente ...
        
        # ‚ú® NUEVO: A√±adir normalizer
        self.taxonomy_normalizer = TaxonomyNormalizer()
        
        # Validar cobertura al cargar
        coverage = self._validate_coverage()
        print(f"   üìä Taxonomy coverage: {coverage['coverage_percent']:.1f}%")
    
    def _validate_coverage(self):
        """Valida cobertura taxon√≥mica del √≠ndice"""
        from collections import Counter
        
        train_types = [
            m.get('dominant_type', m.get('damage_type', 'unknown'))
            for m in self.metadata
        ]
        
        distribution = Counter(train_types)
        
        covered = sum(
            count for dtype, count in distribution.items()
            if dtype in self.taxonomy_normalizer.SEMANTIC_MAPPING
        )
        
        return {
            "total_crops": len(self.metadata),
            "covered_crops": covered,
            "coverage_percent": covered / len(self.metadata) * 100,
            "distribution": dict(distribution)
        }
    
    def search(self, query_embedding, k=5, filters=None):
        # ... b√∫squeda FAISS existente ...
        
        # ‚ú® MODIFICAR: Normalizar despu√©s de b√∫squeda
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx == -1:
                continue
            
            meta = self.metadata[idx]
            train_type = meta.get('dominant_type', meta.get('damage_type', 'unknown'))
            
            # ‚ú® NUEVO: Normalizar tipo
            normalized = self.taxonomy_normalizer.normalize(train_type)
            
            result = SearchResult(
                index=int(idx),
                distance=float(dist),
                crop_path=meta.get('crop_path', ''),
                damage_type=normalized['test_label'],        # ‚ú® NORMALIZADO
                damage_type_original=train_type,            # ‚ú® MANTENER ORIGINAL
                damage_type_confidence=normalized['confidence'], # ‚ú® CONFIANZA
                image_path=meta.get('source_image', ''),
                bbox=meta.get('cluster_bbox', meta.get('bbox', [])),
                spatial_zone=meta.get('spatial_zone', 'unknown'),
                metadata=meta
            )
            
            results.append(result)
            
            if len(results) >= k:
                break
        
        return results


1.3 Actualizar SearchResult
Archivo: src/core/rag/retriever.py
@dataclass
class SearchResult:
    """Resultado de una b√∫squeda"""
    index: int
    distance: float
    crop_path: str
    damage_type: str                    # ‚ú® Ahora normalizado
    damage_type_original: str = ""      # ‚ú® NUEVO
    damage_type_confidence: float = 1.0 # ‚ú® NUEVO
    image_path: str = ""
    bbox: List[float] = None
    spatial_zone: str = ""
    metadata: Dict = None


üìù PASO 2: √çNDICE COMPLEMENTARIO (3 horas)
Repositorio: RAG-multimodal/ (generaci√≥n de embeddings)
2.1 Seleccionar Im√°genes Multi-Defecto 
Archivo: scripts/select_multidefect_images.py
from pathlib import Path
import json
from collections import Counter

def select_rich_images(train_dir: Path, min_defects: int = 3):
    """
    Selecciona im√°genes con ‚â•3 defectos para √≠ndice complementario
    
    Justificaci√≥n:
    - Im√°genes con m√∫ltiples defectos ‚Üí Mayor diversidad en un solo embedding
    - Mejor representaci√≥n de casos reales (veh√≠culos con m√∫ltiples da√±os)
    """
    
    LABEL_MAPPING = {
        "1": "Scratch", "2": "Dent", "3": "Degraded varnish",
        "4": "Scratch", "5": "Crack", "6": "Missing part",
        "7": "Missing part", "8": "Deviated part"
    }
    
    selected = []
    stats = {
        'total_images': 0,
        'selected_images': 0,
        'total_defects_selected': 0,
        'damage_distribution': Counter()
    }
    
    for img_path in sorted(train_dir.glob("*.jpg")):
        stats['total_images'] += 1
        
        json_path = img_path.with_suffix('.json').with_name(
            img_path.stem.replace('_imageDANO_original', '_labelDANO_modificado.json')
        )
        
        if not json_path.exists():
            continue
        
        with open(json_path) as f:
            data = json.load(f)
        
        # Contar defectos
        defect_labels = [
            shape['label'] for shape in data['shapes']
            if shape['shape_type'] == 'polygon'
        ]
        
        if len(defect_labels) >= min_defects:
            # Mapear a taxonom√≠a de test
            test_damages = [LABEL_MAPPING.get(label, "Unknown") for label in defect_labels]
            
            selected.append({
                'image_path': img_path,
                'json_path': json_path,
                'defect_count': len(defect_labels),
                'damage_types': list(set(test_damages)),
                'damage_counts': dict(Counter(test_damages))
            })
            
            stats['selected_images'] += 1
            stats['total_defects_selected'] += len(defect_labels)
            stats['damage_distribution'].update(test_damages)
    
    print(f"\n{'='*70}")
    print(f"SELECCI√ìN DE IM√ÅGENES MULTI-DEFECTO")
    print(f"{'='*70}")
    print(f"Total im√°genes analizadas: {stats['total_images']}")
    print(f"Im√°genes seleccionadas (‚â•{min_defects} defectos): {stats['selected_images']}")
    print(f"Total defectos en selecci√≥n: {stats['total_defects_selected']}")
    print(f"Promedio defectos/imagen: {stats['total_defects_selected']/stats['selected_images']:.1f}")
    
    print(f"\nDistribuci√≥n de tipos de da√±o:")
    for dtype, count in stats['damage_distribution'].most_common():
        print(f"  - {dtype:20}: {count:4} ({count/stats['total_defects_selected']*100:5.1f}%)")
    
    return selected, stats

if __name__ == "__main__":
    train_dir = Path("data/raw/train_test_split/train")
    
    selected, stats = select_rich_images(train_dir, min_defects=3)
    
    # Guardar manifest
    import pickle
    output_path = Path("data/processed/multidefect_images_manifest.pkl")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'wb') as f:
        pickle.dump({'images': selected, 'stats': stats}, f)
    
    print(f"\n‚úÖ Manifest guardado: {output_path}")


2.2 Generar √çndice Complementario 
Archivo: scripts/build_complementary_index.py
from pathlib import Path
import json
import pickle
import numpy as np
import faiss
from collections import Counter
from src.core.embeddings.dinov3_vitl_embedder import DINOv3ViTLEmbedder

def build_complementary_index(
    manifest_path: Path,
    output_dir: Path
):
    """
    Genera √≠ndice FAISS de im√°genes COMPLETAS multi-defecto
    
    Ventajas vs √≠ndice de crops:
    1. Alineaci√≥n sem√°ntica con queries de evaluaci√≥n (im√°genes completas)
    2. Contexto global preservado (m√∫ltiples defectos visibles)
    3. Sin p√©rdida de informaci√≥n por cropping
    """
    
    # Cargar manifest
    with open(manifest_path, 'rb') as f:
        data = pickle.load(f)
    
    image_list = data['images']
    
    print(f"\n{'='*70}")
    print(f"CONSTRUCCI√ìN DE √çNDICE COMPLEMENTARIO")
    print(f"{'='*70}")
    print(f"Im√°genes a indexar: {len(image_list)}\n")
    
    embedder = DINOv3ViTLEmbedder()
    
    embeddings = []
    metadata = []
    
    for i, img_meta in enumerate(image_list, 1):
        img_path = img_meta['image_path']
        
        if i % 50 == 0:
            print(f"  Procesando {i}/{len(image_list)}...")
        
        # Generar embedding de imagen COMPLETA
        embedding = embedder.generate_embedding(img_path, normalize=True)
        embeddings.append(embedding)
        
        # Metadata enriquecida (taxonom√≠a ya normalizada)
        meta = {
            'image_id': img_path.stem,
            'image_path': str(img_path),
            'image_type': 'full_image',  # ‚Üê Distinguir de crops
            
            # Da√±os (YA en taxonom√≠a de test)
            'all_damage_types': img_meta['damage_types'],
            'damage_counts': img_meta['damage_counts'],
            'dominant_damage': max(img_meta['damage_counts'].items(), key=lambda x: x[1])[0],
            'total_defects': img_meta['defect_count'],
            
            # Alias para compatibilidad con DualRetriever
            'damage_type': max(img_meta['damage_counts'].items(), key=lambda x: x[1])[0],
            
            # Embedding info
            'embedding_index': len(embeddings) - 1,
            'embedding_model': 'dinov3-vitl16-fullimage',
            'embedding_dim': 1024
        }
        
        metadata.append(meta)
    
    # Construir √≠ndice FAISS
    embeddings = np.vstack(embeddings).astype('float32')
    
    print(f"\n{'='*70}")
    print(f"CONSTRUYENDO √çNDICE FAISS")
    print(f"{'='*70}")
    print(f"Vectores: {len(embeddings)}")
    print(f"Dimensi√≥n: {embeddings.shape[1]}")
    
    # Para <1000 im√°genes, usar Flat (b√∫squeda exacta)
    if len(embeddings) < 1000:
        index = faiss.IndexFlatL2(1024)
        print(f"Tipo √≠ndice: IndexFlatL2 (exact search)")
    else:
        # Para ‚â•1000, usar HNSW
        index = faiss.IndexHNSWFlat(1024, 32)
        index.hnsw.efConstruction = 200
        index.hnsw.efSearch = 64
        print(f"Tipo √≠ndice: IndexHNSWFlat (approximate search)")
    
    index.add(embeddings)
    
    print(f"Vectores indexados: {index.ntotal}")
    
    # Guardar
    output_dir.mkdir(parents=True, exist_ok=True)
    
    index_path = output_dir / "complementary.index"
    faiss.write_index(index, str(index_path))
    
    metadata_path = output_dir / "complementary_metadata.pkl"
    with open(metadata_path, 'wb') as f:
        pickle.dump(metadata, f)
    
    config_path = output_dir / "complementary_config.json"
    with open(config_path, 'w') as f:
        json.dump({
            'index_type': index.__class__.__name__,
            'n_vectors': len(embeddings),
            'embedding_dim': 1024,
            'embedding_strategy': 'full_image',
            'taxonomy': 'test_aligned',
            'min_defects_per_image': 3
        }, f, indent=2)
    
    print(f"\n{'='*70}")
    print(f"‚úÖ √çNDICE COMPLEMENTARIO GENERADO")
    print(f"{'='*70}")
    print(f"Index: {index_path}")
    print(f"Metadata: {metadata_path}")
    print(f"Config: {config_path}\n")

if __name__ == "__main__":
    manifest_path = Path("data/processed/multidefect_images_manifest.pkl")
    output_dir = Path("outputs/vector_indices/complementary_fullimage")
    
    build_complementary_index(manifest_path, output_dir)

2.3 Implementar Dual Retriever
from pathlib import Path
from typing import List
from .retriever import DamageRAGRetriever, SearchResult
import numpy as np

class DualRetriever:
    """
    Dual retrieval strategy:
    1. Prioritize full-image index (high semantic similarity expected)
    2. Fallback to crop-level index if similarity < threshold
    
    Fundamento cient√≠fico:
    - Full-images: Better semantic alignment with evaluation queries
    - Crops: Better localization precision
    - Hybrid approach: ColBERT-style (Khattab & Zaharia, NeurIPS 2020)
    """
    
    def __init__(
        self,
        crop_index_path: Path,
        crop_metadata_path: Path,
        fullimage_index_path: Path,
        fullimage_metadata_path: Path,
        similarity_threshold: float = 0.3
    ):
        """
        Args:
            similarity_threshold: Si dist < (2 - 2*threshold), usar full-image
                                 Ejemplo: threshold=0.3 ‚Üí usar si dist<1.4 (sim>30%)
        """
        print(f"\n{'='*70}")
        print(f"üîß INICIALIZANDO DUAL RETRIEVER")
        print(f"{'='*70}")
        
        # Cargar retriever de crops (existente)
        print("üì¶ Cargando crop-level retriever...")
        self.crop_retriever = DamageRAGRetriever(
            index_path=crop_index_path,
            metadata_path=crop_metadata_path
        )
        
        # Cargar retriever de full-images (nuevo)
        print("üì¶ Cargando full-image retriever...")
        self.fullimage_retriever = DamageRAGRetriever(
            index_path=fullimage_index_path,
            metadata_path=fullimage_metadata_path
        )
        
        self.similarity_threshold = similarity_threshold
        self.dist_threshold = 2 - 2 * similarity_threshold
        
        print(f"\n‚öôÔ∏è  Configuraci√≥n:")
        print(f"   - Similarity threshold: {similarity_threshold:.2f}")
        print(f"   - Distance threshold: {self.dist_threshold:.2f}")
        print(f"   - Strategy: Use full-image if dist < {self.dist_threshold:.2f}")
        print(f"{'='*70}\n")
    
    def search(
        self,
        query_embedding: np.ndarray,
        k: int = 5,
        filters: dict = None
    ) -> List[SearchResult]:
        """
        B√∫squeda dual con fallback autom√°tico
        """
        # 1. Intentar con full-image retriever primero
        fullimage_results = self.fullimage_retriever.search(
            query_embedding,
            k=k,
            filters=filters
        )
        
        # 2. Evaluar calidad de resultados
        if fullimage_results and fullimage_results[0].distance < self.dist_threshold:
            # Similitud suficientemente alta ‚Üí usar full-image results
            for result in fullimage_results:
                result.retrieval_source = "full_image"  # Tag para debugging
            
            return fullimage_results
        
        # 3. Fallback: usar crop retriever
        crop_results = self.crop_retriever.search(
            query_embedding,
            k=k,
            filters=filters
        )
        
        for result in crop_results:
            result.retrieval_source = "crop"  # Tag para debugging
        
        return crop_results
    
    def get_stats(self) -> dict:
        """Estad√≠sticas de ambos √≠ndices"""
        return {
            'crop_index': {
                'n_vectors': self.crop_retriever.index.ntotal,
                'embedding_dim': self.crop_retriever.embedding_dim
            },
            'fullimage_index': {
                'n_vectors': self.fullimage_retriever.index.ntotal,
                'embedding_dim': self.fullimage_retriever.embedding_dim
            },
            'config': {
                'similarity_threshold': self.similarity_threshold,
                'distance_threshold': self.dist_threshold
            }
        }


üìù PASO 3: INTEGRACI√ìN EN BENCHMARKING
Repositorio: Herramienta de benchmarking (separado)
3.1 Modificar prompt_builder.py
Archivo: rag/prompt_builder.py
class RAGPromptBuilder:
    """
    Constructor de prompts con contexto RAG
    
    Mejoras:
    - Usa labels normalizados (Scratch vs surface_scratch)
    - Formatea zonas espaciales en lenguaje natural
    - A√±ade indicadores de confianza
    """
    
    def inject_rag_context(
        self,
        original_prompt: str,
        search_results: List,
        max_examples: int = 3
    ) -> str:
        """
        Inyecta contexto RAG normalizado en el prompt
        """
        
        if not search_results:
            return original_prompt
        
        # Construir contexto con labels NORMALIZADOS
        context_parts = [
            "\n## üîç Similar Cases from Verified Database:\n",
            "The following examples show similar damage patterns:\n"
        ]
        
        for i, result in enumerate(search_results[:max_examples], 1):
            # Labels YA normalizados por TaxonomyNormalizer
            context_parts.append(f"\n### Example {i}:")
            context_parts.append(f"- **Damage Type**: {result.damage_type}")  # ‚úÖ Normalizado
            context_parts.append(f"- **Vehicle Area**: {self._format_zone(result.spatial_zone)}")
            context_parts.append(f"- **Similarity**: {(1 - result.distance) * 100:.1f}%")
            
            # Indicador de fuente (crop vs full-image)
            if hasattr(result, 'retrieval_source'):
                source_emoji = "üñºÔ∏è" if result.retrieval_source == "full_image" else "‚úÇÔ∏è"
                context_parts.append(f"- **Source**: {source_emoji} {result.retrieval_source}")
            
            # Indicador de confianza (si disponible)
            if hasattr(result, 'damage_type_confidence') and result.damage_type_confidence < 0.9:
                context_parts.append(f"- **Note**: Approximate match (confidence: {result.damage_type_confidence:.0%})")
        
        context_parts.append("\n---\n")
        context_parts.append(original_prompt)
        
        return "\n".join(context_parts)
    
    def _format_zone(self, spatial_zone: str) -> str:
        """Traduce zonas espaciales a lenguaje natural"""
        zone_map = {
            "top_left": "Upper left area",
            "top_center": "Upper center",
            "top_right": "Upper right area",
            "middle_left": "Left side",
            "middle_center": "Center",
            "middle_right": "Right side",
            "bottom_left": "Lower left area",
            "bottom_center": "Lower center",
            "bottom_right": "Lower right area"
        }
        return zone_map.get(spatial_zone, spatial_zone)

3.2 Actualizar config.yaml
Archivo: config.yaml
rag_config:
  enabled: true
  
  # Dual retrieval configuration
  use_dual_retrieval: true  # ‚ú® NUEVO
  
  # Crop-level index (existente)
  crop_index_path: vector_indices/dinov3_20251104
  
  # Full-image index (nuevo)
  fullimage_index_path: vector_indices/complementary_fullimage  # ‚ú® NUEVO
  
  # Retrieval parameters
  embedder_type: dinov3
  top_k: 5
  similarity_threshold: 0.3  # ‚ú® NUEVO: umbral para dual retrieval
  max_examples_in_prompt: 3
  
  # Model configuration
  modelo_con_rag: qwen3-vl:4b


3.3 Modificar main.py (inicializaci√≥n RAG, en la herramienta de benchmarking)
Archivo: main.py
def inicializar_rag(config):
    """
    Initializes RAG components with dual retrieval support
    """
    if not RAG_AVAILABLE:
        return None, None, None
    
    rag_config = config.get("rag_config", {})
    
    if not rag_config.get("enabled", False):
        print("‚ÑπÔ∏è  RAG disabled in configuration")
        return None, None, None
    
    print("\n" + "="*70)
    print("üîß INITIALIZING RAG SYSTEM")
    print("="*70)
    
    try:
        # ‚ú® NUEVO: Dual retrieval support
        use_dual = rag_config.get("use_dual_retrieval", False)
        
        if use_dual:
            print("üì¶ Loading DUAL retriever (crop + full-image)...")
            
            from rag import DualRetriever
            
            crop_index_dir = Path(rag_config.get("crop_index_path"))
            fullimage_index_dir = Path(rag_config.get("fullimage_index_path"))
            
            retriever = DualRetriever(
                crop_index_path=crop_index_dir / "indexhnswflat_clustered.index",
                crop_metadata_path=crop_index_dir / "metadata_clustered.pkl",
                fullimage_index_path=fullimage_index_dir / "complementary.index",
                fullimage_metadata_path=fullimage_index_dir / "complementary_metadata.pkl",
                similarity_threshold=rag_config.get("similarity_threshold", 0.3)
            )
            
            stats = retriever.get_stats()
            print(f"   ‚úÖ Crop index: {stats['crop_index']['n_vectors']} vectors")
            print(f"   ‚úÖ Full-image index: {stats['fullimage_index']['n_vectors']} vectors")
            print(f"   ‚úÖ Threshold: {stats['config']['similarity_threshold']:.2f}")
        
        else:
            print("üì¶ Loading single retriever (crop-only)...")
            
            from rag import DamageRAGRetriever
            
            index_dir = Path(rag_config.get("crop_index_path"))
            
            retriever = DamageRAGRetriever(
                index_path=index_dir / "indexhnswflat_clustered.index",
                metadata_path=index_dir / "metadata_clustered.pkl"
            )
            
            print(f"   ‚úÖ Index: {retriever.index.ntotal} vectors")
        
        # Initialize embedder
        embedder_type = rag_config.get("embedder_type", "dinov3")
        print(f"üîß Initializing embedder ({embedder_type})...")
        
        if embedder_type == "dinov3":
            from rag import DINOv3ViTLEmbedder
            embedder = DINOv3ViTLEmbedder()
        else:
            raise NotImplementedError(f"Embedder {embedder_type} not supported")
        
        # Create prompt builder
        from rag import RAGPromptBuilder
        prompt_builder = RAGPromptBuilder()
        
        print("‚úÖ RAG system initialized successfully")
        print("="*70 + "\n")
        
        return retriever, embedder, prompt_builder
    
    except Exception as e:
        print(f"‚ùå Error initializing RAG: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None


### Validaci√≥n Final
```
‚ñ° Ejecutar evaluaci√≥n completa (200 im√°genes)
‚ñ° Generar reporte comparativo
‚ñ° Documentar resultados
‚ñ° Actualizar README.md
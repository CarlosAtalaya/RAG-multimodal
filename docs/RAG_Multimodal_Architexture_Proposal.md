# ğŸš— RAG Multimodal - Dataset Balanceado con Contexto Enriquecido

## ğŸ“‹ Ãndice

1. [VisiÃ³n General](#-visiÃ³n-general)
2. [Arquitectura del Sistema](#-arquitectura-del-sistema)
3. [Dataset](#-dataset)
4. [MÃ³dulos del Sistema](#-mÃ³dulos-del-sistema)
5. [Pipeline de ImplementaciÃ³n](#-pipeline-de-implementaciÃ³n)
6. [Estructura de Archivos](#-estructura-de-archivos)
7. [Esquema de Metadata](#-esquema-de-metadata)
8. [ConfiguraciÃ³n y ParÃ¡metros](#-configuraciÃ³n-y-parÃ¡metros)
9. [Resultados Esperados](#-resultados-esperados)
10. [PrÃ³ximos Pasos](#-prÃ³ximos-pasos)

---

## ğŸ¯ VisiÃ³n General

### Objetivo

Implementar un sistema RAG (Retrieval-Augmented Generation) multimodal que procese un dataset balanceado de imÃ¡genes vehiculares con y sin daÃ±os, generando embeddings hÃ­bridos (visual + textual) contextualizados para bÃºsqueda semÃ¡ntica avanzada.

### CaracterÃ­sticas Principales

- âœ… **Dataset Balanceado**: 50% imÃ¡genes con daÃ±o (ko) + 50% sin daÃ±o (ok)
- âœ… **Embeddings HÃ­bridos**: Visual (DINOv3 1024d) + Textual (SBERT 384d) = 1408 dimensiones
- âœ… **Pesos 50/50**: Equilibrio entre informaciÃ³n visual y semÃ¡ntica
- âœ… **Contexto Enriquecido**: Descripciones textuales ricas con zona, parte especÃ­fica y tipos de daÃ±o
- âœ… **Ãndice Ãšnico FAISS**: UnificaciÃ³n de crops damaged + clean con filtros avanzados
- âœ… **Crops Inteligentes**: Clusterizados para daÃ±os, grid adaptativo para imÃ¡genes limpias

---

## ğŸ—ï¸ Arquitectura del Sistema

```
Dataset Split 2 (552 imÃ¡genes)
           â†“
    Â¿Tiene daÃ±o?
     â†™         â†˜
   SÃ          NO
(276 ko)    (276 ok)
    â†“            â†“
Clustered    Vehicle Detector
  Crop       + Grid Crop
Generator      Generator
    â†“            â†“
~850 crops   ~1,500-2,000 crops
(448Ã—448)       (448Ã—448)
    â†“            â†“
Damage       Clean
Contextualizer  Contextualizer
    â†“            â†“
Contexto     Contexto
CON daÃ±o     SIN daÃ±o
    â†“            â†“
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â†“
   Multimodal Embedder
   (50% Visual + 50% Text)
          â†“
   Embeddings HÃ­bridos
      (1408 dims)
          â†“
   Ãndice FAISS Unificado
    (IndexHNSWFlat)
          â†“
  Retriever con Filtros
  (zona + has_damage)
```

---

## ğŸ“Š Dataset

### Estructura del Dataset Split 2

```
data/raw/dataset_split_2/
â”œâ”€â”€ ImÃ¡genes CON daÃ±o (276 imÃ¡genes)
â”‚   â”œâ”€â”€ zona1_ko_2_3_1554817134014_zona_4_imageDANO_original.jpg
â”‚   â”œâ”€â”€ zona1_ko_2_3_1554817134014_zona_4_imageDANO_original.json          # Ground truth
â”‚   â””â”€â”€ zona1_ko_2_3_1554817134014_zona_4_labelDANO_modificado.json        # SegmentaciÃ³n
â”‚
â””â”€â”€ ImÃ¡genes SIN daÃ±o (276 imÃ¡genes)
    â”œâ”€â”€ zona1_ok_2_3_1554373063646_zona_6_imageDANO_original.jpg
    â””â”€â”€ zona1_ok_2_3_1554373063646_zona_6_imageDANO_original.json          # Ground truth "No damage"
```

### CaracterÃ­sticas

| Aspecto | Valor |
|---------|-------|
| **Total imÃ¡genes** | 552 |
| **Con daÃ±o (ko)** | 276 (50%) |
| **Sin daÃ±o (ok)** | 276 (50%) |
| **Formato** | JPG |
| **Anotaciones** | JSON (LabelMe format) |

### Naming Convention

```
zona1_{ko|ok}_2_3_{timestamp}_zona_{1-10}_imageDANO_original.jpg
  â”‚     â”‚                         â”‚
  â”‚     â”‚                         â””â”€ Zona del vehÃ­culo (1-10)
  â”‚     â””â”€ ko: con daÃ±o | ok: sin daÃ±o
  â””â”€ Identificador del dataset
```

### Zonas del VehÃ­culo

| Zona | Nombre TÃ©cnico | DescripciÃ³n | Ãrea |
|------|----------------|-------------|------|
| 1 | front_left_fender | Guardabarros delantero izquierdo | frontal |
| 2 | hood_center | CapÃ³ central | frontal |
| 3 | front_right_fender | Guardabarros delantero derecho | frontal |
| 4 | rear_left_quarter | Panel trasero izquierdo | posterior |
| 5 | rear_bumper | Parachoques trasero | posterior |
| 6 | rear_right_quarter | Panel trasero derecho | posterior |
| 7 | driver_side_door | Puerta del conductor (izquierda) | lateral_left |
| 8 | driver_side_rocker | Panel lateral del conductor | lateral_left |
| 9 | passenger_side_door | Puerta del pasajero (derecha) | lateral_right |
| 10 | passenger_side_rocker | Panel lateral del pasajero | lateral_right |

### Tipos de DaÃ±o

| Label | Nombre CanÃ³nico | DescripciÃ³n |
|-------|-----------------|-------------|
| 1 | surface_scratch | AraÃ±azo superficial |
| 2 | dent | Abolladura |
| 3 | paint_peeling | Desprendimiento de pintura |
| 4 | deep_scratch | AraÃ±azo profundo |
| 5 | crack | Grieta |
| 6 | missing_part | Parte faltante |
| 7 | missing_accessory | Accesorio faltante |
| 8 | misaligned_part | Parte desalineada |

---

## ğŸ§© MÃ³dulos del Sistema

### 1. Vehicle Detector ğŸš—

**UbicaciÃ³n**: `src/core/preprocessing/vehicle_detector.py`

**FunciÃ³n**: Detectar el coche principal en imÃ¡genes sin daÃ±o para centrar los crops.

**TecnologÃ­a**: YOLOv8 pre-entrenado en COCO (clase 'car')

**Proceso**:
1. Detectar todos los coches en la imagen
2. Seleccionar el bbox mÃ¡s grande (coche principal)
3. Expandir bbox con margen (10-15%) para contexto
4. Retornar coordenadas ajustadas

**Output**:
```python
{
    'bbox': [x1, y1, x2, y2],
    'confidence': 0.95,
    'vehicle_area_ratio': 0.68  # % de imagen ocupado
}
```

**Ventajas**:
- âœ… Centra crops en el vehÃ­culo
- âœ… Minimiza fondo innecesario
- âœ… Mejora calidad de embeddings visuales

---

### 2. Grid Crop Generator ğŸ“

**UbicaciÃ³n**: `src/core/preprocessing/grid_crop_generator.py`

**FunciÃ³n**: Generar grid de crops 448Ã—448 para imÃ¡genes sin daÃ±o.

**Estrategia**:
- Sliding window dentro del bbox del vehÃ­culo
- Overlap inteligente (20-30%) para cobertura completa
- Filtrado: solo crops con >70% Ã¡rea del coche

**ParÃ¡metros**:
```python
crop_size = 448
overlap = 0.25  # 25%
min_vehicle_ratio = 0.70  # MÃ­nimo 70% del crop debe ser coche
```

**Output Esperado por Imagen**:
- ImÃ¡genes grandes: 6-10 crops
- ImÃ¡genes medianas: 4-6 crops
- ImÃ¡genes pequeÃ±as: 2-4 crops

**Total Estimado**: ~1,500-2,000 crops para 276 imÃ¡genes ok

---

### 3. Clustered Crop Generator (Modificado) ğŸ”§

**UbicaciÃ³n**: `src/core/preprocessing/clustered_crop_generator.py`

**Cambios Clave**:

âŒ **Eliminado**: Padding adaptativo con color gris
```python
# ANTES (NO usar)
canvas = np.full((448, 448, 3), [114, 114, 114], dtype=np.uint8)
canvas[y:y+h, x:x+w] = crop
```

âœ… **Nuevo**: Imagen original completa
```python
# AHORA (usar)
if merged_bbox.width > 448 or merged_bbox.height > 448:
    # Resize proporcional manteniendo aspecto
    scale = min(448 / merged_bbox.width, 448 / merged_bbox.height)
    crop_resized = cv2.resize(crop, None, fx=scale, fy=scale)
else:
    # Crop directo sin padding
    crop_resized = crop
```

**Ventajas**:
- âœ… Sin artifacts de padding
- âœ… Solo pÃ­xeles reales del vehÃ­culo
- âœ… Mejor calidad visual para DINOv3

**Output Esperado**: ~850 crops para 276 imÃ¡genes ko

---

### 4. Damage Contextualizer ğŸ“

**UbicaciÃ³n**: `src/core/embeddings/damage_contextualizer.py`

**FunciÃ³n**: Generar descripciones textuales enriquecidas para cada crop.

#### Para ImÃ¡genes CON DaÃ±o

**MÃ©todo**: `build_damage_context(metadata: Dict) -> str`

**Estructura**:
1. Zona del vehÃ­culo (del naming)
2. Parte especÃ­fica (DINOv3 + heurÃ­stica)
3. Tipos de daÃ±o con descripciÃ³n breve
4. RelaciÃ³n espacial entre daÃ±os

**Ejemplo Output**:
```
Vehicle zone: rear_left_quarter (posterior area).
Affected part: Rear left corner panel near bumper junction.
Damage types: Surface scratch (minor abrasion, 2 instances), Dent (metal deformation, 1 instance).
Spatial pattern: Scratches clustered around dent, suggesting single impact event.
```

**Longitud**: ~150-200 caracteres (conciso pero informativo)

#### Para ImÃ¡genes SIN DaÃ±o

**MÃ©todo**: `build_clean_context(metadata: Dict) -> str`

**Estructura**:
1. Zona del vehÃ­culo
2. Parte especÃ­fica (DINOv3)
3. CondiciÃ³n superficie (minimalista)

**Ejemplo Output**:
```
Vehicle zone: hood_center (frontal area).
Inspected part: Central hood panel.
Surface condition: Clean paint, no scratches or dents detected.
Panel integrity: Normal alignment, intact surface.
```

**Longitud**: ~120-150 caracteres

#### Estrategia para "Parte EspecÃ­fica" con DINOv3

```python
prompt = f"""
Analyze this cropped vehicle image showing the {zone_description} area.
Identify the SPECIFIC car part visible (e.g., 'front bumper', 'door handle area', 'quarter panel edge').
Be precise and concise. Format: "specific_part_name"
"""
```

**Fallback**: Si DINOv3 falla, usar heurÃ­stica basada en zona + posiciÃ³n relativa.

---

### 5. Multimodal Embedder (Modificado) ğŸ§ 

**UbicaciÃ³n**: `src/core/embeddings/multimodal_embedder.py`

**Cambios Principales**:

âœ… **Pesos Ajustados a 50/50**
```python
# ANTES
visual_weight = 0.6  # 60%
text_weight = 0.4    # 40%

# AHORA
visual_weight = 0.5  # 50%
text_weight = 0.5    # 50%
```

**JustificaciÃ³n**:
- Equilibrio perfecto entre informaciÃ³n visual y semÃ¡ntica
- Mejora retrieval cuando similitud visual es baja pero contexto es similar
- Base cientÃ­fica: Papers de CLIP, BLIP-2 usan fusiÃ³n balanceada

#### DimensiÃ³n de Embeddings HÃ­bridos

```
Visual (DINOv3):           1024 dims
Textual (Sentence-BERT):    384 dims
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total (ConcatenaciÃ³n):     1408 dims
```

#### Â¿Por quÃ© 1408 dims es Ã³ptimo?

| Aspecto | EvaluaciÃ³n |
|---------|-----------|
| Capacidad FAISS | âœ… Excelente (<10K dims es Ã³ptimo) |
| Overfitting | âœ… No hay riesgo con 2,500 samples |
| Velocidad bÃºsqueda | âœ… <50ms por query |
| Calidad informaciÃ³n | âœ… Preserva ambas modalidades |
| Alternativa PCA | âŒ PerderÃ­a informaciÃ³n valiosa |

**ConclusiÃ³n**: âœ… Mantener 1408 dims

#### Pipeline de GeneraciÃ³n

```python
def generate_hybrid_embedding(self, image_path, metadata):
    # 1. Embedding Visual
    visual_emb = self.visual_embedder.generate_embedding(image_path)
    # Shape: (1024,)
    
    # 2. Contexto Textual
    if metadata['has_damage']:
        text_desc = self.contextualizer.build_damage_context(metadata)
    else:
        text_desc = self.contextualizer.build_clean_context(metadata)
    
    # 3. Embedding Textual
    text_emb = self.text_embedder.encode(text_desc)
    # Shape: (384,)
    
    # 4. FusiÃ³n Ponderada 50/50
    hybrid_emb = np.concatenate([
        visual_emb * self.visual_weight,  # 0.5
        text_emb * self.text_weight       # 0.5
    ])
    # Shape: (1408,)
    
    # 5. NormalizaciÃ³n L2
    hybrid_emb = hybrid_emb / np.linalg.norm(hybrid_emb)
    
    return hybrid_emb, text_desc
```

---

### 6. Unified FAISS Index Builder ğŸ—„ï¸

**UbicaciÃ³n**: `src/core/vector_store/unified_faiss_builder.py`

**FunciÃ³n**: Construir Ã­ndice FAISS Ãºnico con todos los crops (damaged + clean).

**ConfiguraciÃ³n**:
```python
# Para <10K vectores: IndexHNSWFlat
index = faiss.IndexHNSWFlat(1408, 32)
index.hnsw.efConstruction = 200
index.hnsw.efSearch = 64
```

**ParÃ¡metros**:
- **M**: 32 (conectividad del grafo HNSW)
- **efConstruction**: 200 (calidad durante indexaciÃ³n)
- **efSearch**: 64 (calidad durante bÃºsqueda)

**TamaÃ±o Estimado**:
- ~2,500 vectores Ã— 1408 dims Ã— 4 bytes = ~14 MB
- Con overhead HNSW: ~20-25 MB

---

### 7. Unified Retriever con Filtros ğŸ”

**UbicaciÃ³n**: `src/core/rag/retriever_unified.py`

**FunciÃ³n**: BÃºsqueda semÃ¡ntica con filtros pre-FAISS.

#### Filtros Soportados

| Filtro | Tipo | DescripciÃ³n |
|--------|------|-------------|
| vehicle_zone | str o List[str] | Zona(s) del vehÃ­culo (1-10) |
| has_damage | bool | Con daÃ±o (True) o sin daÃ±o (False) |
| damage_type | str o List[str] | Tipo(s) de daÃ±o especÃ­fico(s) |

#### Ejemplo de Uso

```python
# Buscar solo zona 4 con daÃ±o
results = retriever.search(
    query_embedding=query_emb,
    k=5,
    filters={
        'vehicle_zone': '4',
        'has_damage': True
    }
)

# Buscar imÃ¡genes limpias en zonas frontales
results = retriever.search(
    query_embedding=query_emb,
    k=10,
    filters={
        'vehicle_zone': ['1', '2', '3'],  # Zonas frontales
        'has_damage': False
    }
)
```

#### Flujo de BÃºsqueda

```
Query Embedding
      â†“
Aplicar Filtros en Metadata
      â†“
Construir Subset de Ãndices VÃ¡lidos
      â†“
BÃºsqueda FAISS en Subset
      â†“
Remapear Ãndices al Ãndice Principal
      â†“
Top-K Resultados
```

---

## ğŸš€ Pipeline de ImplementaciÃ³n

### FASE 1: GeneraciÃ³n de Crops ğŸ“¸

**Script**: `scripts/phase1_generate_crops.py`  
**DuraciÃ³n Estimada**: 15-20 minutos

#### Proceso

```
Dataset Split 2 (552 imÃ¡genes)
           â†“
    Â¿Tipo de imagen?
     â†™         â†˜
   ko          ok
(276)         (276)
    â†“            â†“
Clustered    Vehicle Detector
  Crop       + Grid Crop
Generator      Generator
    â†“            â†“
~850 crops   ~1,500-2,000 crops
    â†“            â†“
damaged/     clean/
```

#### Acciones

1. **Inicializar componentes**:
```python
vehicle_detector = VehicleDetector()  # YOLOv8
grid_generator = GridCropGenerator(crop_size=448, overlap=0.25)
cluster_generator = ClusteredCropGenerator(target_size=448)
```

2. **Procesar imÃ¡genes**:
```python
for image in dataset_split_2:
    if image.has_damage:  # _ko_
        crops = cluster_generator.generate(image)
    else:  # _ok_
        vehicle_bbox = vehicle_detector.detect(image)
        crops = grid_generator.generate(image, vehicle_bbox)
    
    save_crops(crops, output_dir)
```

3. **Guardar metadata preliminar**:
```python
metadata = {
    'crop_id': 'zona1_ko_..._cluster_003',
    'crop_path': '/path/to/crop.jpg',
    'source_image': 'zona1_ko_..._zona_4_imageDANO_original.jpg',
    'has_damage': True,
    'vehicle_zone': '4',
    'zone_description': 'rear_left_quarter',
    'zone_area': 'posterior',
    'crop_type': 'clustered' | 'grid',
    # ... (sin text_description todavÃ­a)
}
```

#### Output

```
data/processed/crops/balanced_dataset/
â”œâ”€â”€ damaged/
â”‚   â”œâ”€â”€ zona1_ko_..._cluster_000.jpg
â”‚   â”œâ”€â”€ zona1_ko_..._cluster_001.jpg
â”‚   â””â”€â”€ ... (~850 crops)
â””â”€â”€ clean/
    â”œâ”€â”€ zona1_ok_..._grid_0_0.jpg
    â”œâ”€â”€ zona1_ok_..._grid_0_1.jpg
    â””â”€â”€ ... (~1,500-2,000 crops)

data/processed/metadata/
â””â”€â”€ balanced_crops_preliminary.json
```

#### MÃ©tricas de Ã‰xito

- âœ… ~850 crops damaged generados
- âœ… ~1,500-2,000 crops clean generados
- âœ… Todos los crops son 448Ã—448 (o proporcionalmente escalados)
- âœ… Crops clean tienen >70% Ã¡rea del vehÃ­culo

---

### FASE 2: GeneraciÃ³n de Contextos Textuales ğŸ“

**Script**: `scripts/phase2_generate_contexts.py`  
**DuraciÃ³n Estimada**: 30-40 minutos (dependiente de DINOv3 API)

#### Proceso

```
Metadata Preliminar
        â†“
  Â¿Tiene daÃ±o?
   â†™         â†˜
 SÃ          NO
  â†“            â†“
Cargar JSON  Contexto
segmentaciÃ³n  limpio
  â†“            â†“
Extraer tipos   â†“
+ relaciones    â†“
espaciales      â†“
  â†“            â†“
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â†“
  Llamar DINOv3
  parte especÃ­fica
        â†“
DamageContextualizer
        â†“
Generar text_description
        â†“
Enriquecer metadata
```

#### Acciones

1. **Cargar metadata preliminar**:
```python
with open('balanced_crops_preliminary.json') as f:
    metadata_list = json.load(f)
```

2. **Para cada crop CON daÃ±o**:
```python
# Cargar JSON de segmentaciÃ³n
segmentation_json = load_segmentation_json(crop.source_image)

# Extraer informaciÃ³n
damage_types = extract_damage_types(segmentation_json)
spatial_relations = analyze_spatial_relations(segmentation_json)

# Obtener parte especÃ­fica con DINOv3
specific_part = dinov3_identify_part(
    crop_path=crop.crop_path,
    zone=crop.zone_description
)

# Generar contexto
text_desc = contextualizer.build_damage_context(
    zone=crop.zone_description,
    specific_part=specific_part,
    damage_types=damage_types,
    spatial_relations=spatial_relations
)
```

3. **Para cada crop SIN daÃ±o**:
```python
# Obtener parte especÃ­fica con DINOv3
specific_part = dinov3_identify_part(
    crop_path=crop.crop_path,
    zone=crop.zone_description
)

# Generar contexto minimalista
text_desc = contextualizer.build_clean_context(
    zone=crop.zone_description,
    specific_part=specific_part
)
```

4. **Enriquecer metadata**:
```python
crop.metadata['text_description'] = text_desc
crop.metadata['specific_part'] = specific_part

if crop.has_damage:
    crop.metadata['damage_descriptions'] = {
        'surface_scratch': 'Minor abrasion, 2 instances',
        'dent': 'Metal deformation, 1 instance'
    }
    crop.metadata['spatial_pattern'] = 'Scratches clustered around dent'
```

#### Output

```
data/processed/metadata/
â””â”€â”€ balanced_crops_enriched.json
```

#### Ejemplo de Metadata Enriquecida

```json
{
  "crop_id": "zona1_ko_..._cluster_003",
  "crop_path": "/path/to/crop.jpg",
  "source_image": "zona1_ko_..._zona_4_imageDANO_original.jpg",
  "has_damage": true,
  "vehicle_zone": "4",
  "zone_description": "rear_left_quarter",
  "zone_area": "posterior",
  "specific_part": "Rear left corner panel near bumper junction",
  "text_description": "Vehicle zone: rear_left_quarter (posterior area). Affected part: Rear left corner panel near bumper junction. Damage types: Surface scratch (minor abrasion, 2 instances), Dent (metal deformation, 1 instance). Spatial pattern: Scratches clustered around dent, suggesting single impact event.",
  "damage_types": ["surface_scratch", "dent"],
  "damage_count": 3,
  "damage_descriptions": {
    "surface_scratch": "Minor abrasion, 2 instances",
    "dent": "Metal deformation, 1 instance"
  },
  "spatial_pattern": "Scratches clustered around dent",
  "crop_type": "clustered"
}
```

#### MÃ©tricas de Ã‰xito

- âœ… Todos los crops tienen text_description
- âœ… Todos los crops tienen specific_part
- âœ… Crops damaged tienen damage_descriptions y spatial_pattern
- âœ… Longitud promedio de descripciones: 150-200 caracteres

---

### FASE 3: GeneraciÃ³n de Embeddings HÃ­bridos ğŸ§ 

**Script**: `scripts/phase3_generate_hybrid_embeddings.py`  
**DuraciÃ³n Estimada**: 20-25 minutos

#### Proceso

```
Metadata Enriquecida
        â†“
MultimodalEmbedder (50/50)
        â†“
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â†“       â†“
DINOv3   Sentence-BERT
Visual   Text
1024d    384d
    â†“       â†“
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â†“
ConcatenaciÃ³n Ponderada
        â†“
NormalizaciÃ³n L2
        â†“
Embeddings HÃ­bridos
      1408d
```

#### Acciones

1. **Inicializar embedder**:
```python
embedder = MultimodalEmbedder(
    visual_weight=0.5,
    text_weight=0.5,
    use_bfloat16=True
)
```

2. **Batch processing**:
```python
batch_size = 16
all_embeddings = []

for batch in batches(crops_metadata, batch_size):
    batch_paths = [crop['crop_path'] for crop in batch]
    
    embeddings, debug_info = embedder.generate_batch_embeddings(
        image_paths=batch_paths,
        metadata_list=batch
    )
    
    all_embeddings.append(embeddings)

final_embeddings = np.vstack(all_embeddings)
# Shape: (N, 1408) donde N ~2,500
```

3. **Guardar embeddings y metadata final**:
```python
# Embeddings
np.save('embeddings.npy', final_embeddings)

# Metadata con Ã­ndices de embeddings
for i, meta in enumerate(crops_metadata):
    meta['embedding_index'] = i
    meta['embedding_model'] = 'hybrid_dinov3_sbert_50_50'
    meta['embedding_norm'] = float(np.linalg.norm(final_embeddings[i]))

with open('metadata_final.json', 'w') as f:
    json.dump(crops_metadata, f, indent=2)
```

#### Output

```
data/processed/embeddings/balanced_hybrid_50_50/
â”œâ”€â”€ embeddings.npy           # (2500, 1408) float32
â”œâ”€â”€ metadata_final.json      # Con embedding_index
â””â”€â”€ generation_info.json     # Info del proceso
```

#### EstadÃ­sticas Esperadas

```
Shape: (2500, 1408)
Dtype: float32
Norma promedio: 1.0000 (Â±0.0001)
Tiempo total: ~20 minutos
Tiempo/crop: ~0.5s
```

#### MÃ©tricas de Ã‰xito

- âœ… Embeddings shape: (N, 1408)
- âœ… Normas promedio: ~1.0 (normalizaciÃ³n L2)
- âœ… Sin NaN o Inf
- âœ… Todos los crops tienen embedding_index

---

### FASE 4: ConstrucciÃ³n Ãndice FAISS ğŸ—„ï¸

**Script**: `scripts/phase4_build_unified_faiss_index.py`  
**DuraciÃ³n Estimada**: 2-3 minutos

#### Proceso

```
Embeddings (2500Ã—1408)
        â†“
IndexHNSWFlat (M=32)
        â†“
AÃ±adir Vectores
        â†“
ValidaciÃ³n
        â†“
Guardar Ãndice + Metadata
```

#### Acciones

1. **Cargar embeddings**:
```python
embeddings = np.load('embeddings.npy').astype('float32')
with open('metadata_final.json') as f:
    metadata = json.load(f)

print(f"Embeddings: {embeddings.shape}")
print(f"Metadata: {len(metadata)} entries")
```

2. **Construir Ã­ndice FAISS**:
```python
import faiss

dim = 1408
M = 32  # Conectividad HNSW

index = faiss.IndexHNSWFlat(dim, M)
index.hnsw.efConstruction = 200
index.hnsw.efSearch = 64

# AÃ±adir vectores
index.add(embeddings)

print(f"Ãndice construido: {index.ntotal} vectores")
```

3. **ValidaciÃ³n**:
```python
# Test de bÃºsqueda
query = embeddings[0:1]
distances, indices = index.search(query, k=5)

print("Top-5 resultados:")
for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
    print(f"{i+1}. Idx={idx}, Dist={dist:.4f}")

# Validar que el primero es Ã©l mismo
assert indices[0][0] == 0
assert distances[0][0] < 0.01
```

4. **Guardar**:
```python
# Ãndice FAISS
faiss.write_index(index, 'index_hnsw_balanced.faiss')

# Metadata (pickle para preservar tipos)
import pickle
with open('metadata_balanced.pkl', 'wb') as f:
    pickle.dump(metadata, f)

# ConfiguraciÃ³n
config = {
    'index_type': 'IndexHNSWFlat',
    'n_vectors': index.ntotal,
    'embedding_dim': dim,
    'M': M,
    'efConstruction': 200,
    'efSearch': 64,
    'data_type': 'balanced_unified',
    'crops_damaged': sum(1 for m in metadata if m['has_damage']),
    'crops_clean': sum(1 for m in metadata if not m['has_damage'])
}

with open('config.json', 'w') as f:
    json.dump(config, f, indent=2)
```

#### Output

```
outputs/vector_indices/balanced_unified/
â”œâ”€â”€ index_hnsw_balanced.faiss    # ~20-25 MB
â”œâ”€â”€ metadata_balanced.pkl         # ~15-20 MB
â””â”€â”€ config.json                   # Config del Ã­ndice
```

#### MÃ©tricas de Ã‰xito

- âœ… Ãndice construido: 2,500 vectores
- âœ… TamaÃ±o razonable: ~20-25 MB
- âœ… ValidaciÃ³n exitosa (self-similarity)
- âœ… Metadata en sync con Ã­ndice

---

### FASE 5: ValidaciÃ³n y Testing âœ…

**Script**: `scripts/phase5_validate_retrieval.py`  
**DuraciÃ³n Estimada**: 5-10 minutos

#### Test 1: Filtros BÃ¡sicos

```python
# Test 1.1: Buscar solo zona 4 con daÃ±o
results = retriever.search(
    query_embedding=test_emb,
    k=5,
    filters={
        'vehicle_zone': '4',
        'has_damage': True
    }
)

print("Test 1.1: Zona 4 con daÃ±o")
for r in results:
    assert r.vehicle_zone == '4'
    assert r.has_damage == True
    print(f"âœ… {r.crop_id} - Zone: {r.zone_description}")

# Test 1.2: Buscar imÃ¡genes limpias frontales
results = retriever.search(
    query_embedding=test_emb,
    k=10,
    filters={
        'vehicle_zone': ['1', '2', '3'],
        'has_damage': False
    }
)

print("\nTest 1.2: Zonas frontales sin daÃ±o")
for r in results:
    assert r.vehicle_zone in ['1', '2', '3']
    assert r.has_damage == False
    print(f"âœ… {r.crop_id} - Zone: {r.zone_description}")
```

#### Test 2: Cobertura de Retrieval

```python
# Test 2.1: Query damaged â†’ Recuperar damaged similares
damaged_crops = [m for m in metadata if m['has_damage']]
sample_damaged = random.sample(damaged_crops, 10)

for crop in sample_damaged:
    query_emb = embeddings[crop['embedding_index']]
    results = retriever.search(query_emb, k=5)
    
    damaged_count = sum(1 for r in results if r.has_damage)
    print(f"Query damaged: {damaged_count}/5 resultados con daÃ±o")
    assert damaged_count >= 3  # Al menos 60% deben ser damaged

# Test 2.2: Query clean â†’ Recuperar clean similares
clean_crops = [m for m in metadata if not m['has_damage']]
sample_clean = random.sample(clean_crops, 10)

for crop in sample_clean:
    query_emb = embeddings[crop['embedding_index']]
    results = retriever.search(query_emb, k=5)
    
    clean_count = sum(1 for r in results if not r.has_damage)
    print(f"Query clean: {clean_count}/5 resultados limpios")
    assert clean_count >= 3  # Al menos 60% deben ser clean
```

#### Test 3: Calidad de Contextos

```python
# Verificar que text_description tiene sentido
for i in range(20):
    meta = metadata[i]
    print(f"\n{meta['crop_id']}")
    print(f"Has damage: {meta['has_damage']}")
    print(f"Zone: {meta['zone_description']}")
    print(f"Text: {meta['text_description'][:150]}...")
    
    # Validaciones bÃ¡sicas
    assert len(meta['text_description']) > 50
    assert meta['zone_description'] in meta['text_description']
    
    if meta['has_damage']:
        assert 'damage' in meta['text_description'].lower()
        assert len(meta['damage_types']) > 0
    else:
        assert 'no damage' in meta['text_description'].lower() or \
               'clean' in meta['text_description'].lower()
```

#### Test 4: VisualizaciÃ³n Manual

```python
# Seleccionar query y visualizar top-5
query_idx = 42
query_meta = metadata[query_idx]
query_emb = embeddings[query_idx]

print(f"\n{'='*70}")
print(f"QUERY: {query_meta['crop_id']}")
print(f"Zone: {query_meta['zone_description']}")
print(f"Has damage: {query_meta['has_damage']}")
print(f"Text: {query_meta['text_description']}")
print(f"{'='*70}\n")

results = retriever.search(query_emb, k=5)

print("TOP-5 RESULTADOS:")
for i, r in enumerate(results, 1):
    print(f"\n{i}. {r.crop_id}")
    print(f"   Distance: {r.distance:.4f}")
    print(f"   Zone: {r.zone_description}")
    print(f"   Has damage: {r.has_damage}")
    print(f"   Text: {r.text_description[:100]}...")
```

#### MÃ©tricas de Ã‰xito

- âœ… Todos los filtros funcionan correctamente
- âœ… Query damaged recupera mayoritariamente damaged
- âœ… Query clean recupera mayoritariamente clean
- âœ… Query zona X recupera mayoritariamente zona X
- âœ… Contextos textuales son coherentes y descriptivos
- âœ… No hay errores de indexaciÃ³n (Ã­ndices fuera de rango)

---

## ğŸ“ Estructura de Archivos

### Estructura Completa del Proyecto

```
RAG-multimodal/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ dataset_split_2/                    # Dataset original (552 imÃ¡genes)
â”‚   â”‚       â”œâ”€â”€ zona1_ko_..._imageDANO_original.jpg
â”‚   â”‚       â”œâ”€â”€ zona1_ko_..._imageDANO_original.json
â”‚   â”‚       â”œâ”€â”€ zona1_ko_..._labelDANO_modificado.json
â”‚   â”‚       â”œâ”€â”€ zona1_ok_..._imageDANO_original.jpg
â”‚   â”‚       â””â”€â”€ zona1_ok_..._imageDANO_original.json
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ crops/
â”‚       â”‚   â””â”€â”€ balanced_dataset/
â”‚       â”‚       â”œâ”€â”€ damaged/                    # ~850 crops (448Ã—448)
â”‚       â”‚       â”‚   â”œâ”€â”€ zona1_ko_..._cluster_000.jpg
â”‚       â”‚       â”‚   â”œâ”€â”€ zona1_ko_..._cluster_001.jpg
â”‚       â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚       â””â”€â”€ clean/                      # ~1,500-2,000 crops (448Ã—448)
â”‚       â”‚           â”œâ”€â”€ zona1_ok_..._grid_0_0.jpg
â”‚       â”‚           â”œâ”€â”€ zona1_ok_..._grid_0_1.jpg
â”‚       â”‚           â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ metadata/
â”‚       â”‚   â”œâ”€â”€ balanced_crops_preliminary.json # Metadata sin contexto textual
â”‚       â”‚   â””â”€â”€ balanced_crops_enriched.json    # Metadata con text_description
â”‚       â”‚
â”‚       â””â”€â”€ embeddings/
â”‚           â””â”€â”€ balanced_hybrid_50_50/
â”‚               â”œâ”€â”€ embeddings.npy              # (2500, 1408) float32
â”‚               â”œâ”€â”€ metadata_final.json         # Metadata con embedding_index
â”‚               â””â”€â”€ generation_info.json        # Info del proceso
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ preprocessing/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ vehicle_detector.py             # âœ¨ NUEVO
â”‚       â”‚   â”œâ”€â”€ grid_crop_generator.py          # âœ¨ NUEVO
â”‚       â”‚   â””â”€â”€ clustered_crop_generator.py     # ğŸ”§ MODIFICADO
â”‚       â”‚
â”‚       â”œâ”€â”€ embeddings/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ damage_contextualizer.py        # âœ¨ NUEVO
â”‚       â”‚   â”œâ”€â”€ multimodal_embedder.py          # ğŸ”§ MODIFICADO
â”‚       â”‚   â”œâ”€â”€ dinov3_vitl_embedder.py         # Existente
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ vector_store/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ unified_faiss_builder.py        # âœ¨ NUEVO
â”‚       â”‚
â”‚       â””â”€â”€ rag/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ retriever_unified.py            # âœ¨ NUEVO
â”‚           â”œâ”€â”€ taxonomy_normalizer.py          # Existente
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase1_generate_crops.py                # âœ¨ NUEVO
â”‚   â”œâ”€â”€ phase2_generate_contexts.py             # âœ¨ NUEVO
â”‚   â”œâ”€â”€ phase3_generate_hybrid_embeddings.py    # âœ¨ NUEVO
â”‚   â”œâ”€â”€ phase4_build_unified_faiss_index.py     # âœ¨ NUEVO
â”‚   â”œâ”€â”€ phase5_validate_retrieval.py            # âœ¨ NUEVO
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ vector_indices/
â”‚       â””â”€â”€ balanced_unified/
â”‚           â”œâ”€â”€ index_hnsw_balanced.faiss       # Ãndice FAISS (~20-25 MB)
â”‚           â”œâ”€â”€ metadata_balanced.pkl           # Metadata (~15-20 MB)
â”‚           â””â”€â”€ config.json                     # ConfiguraciÃ³n del Ã­ndice
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ crop_strategy_config.yaml              # ConfiguraciÃ³n de crops
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ BALANCED_DATASET_ARCHITECTURE.md        # ğŸ“„ ESTE DOCUMENTO
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ“Š Esquema de Metadata

### Metadata Final (JSON)

```json
{
  "crop_id": "zona1_ko_2_3_1554817134014_zona_4_cluster_003",
  "crop_path": "data/processed/crops/balanced_dataset/damaged/zona1_ko_..._cluster_003.jpg",
  "source_image": "zona1_ko_2_3_1554817134014_zona_4_imageDANO_original.jpg",
  
  "has_damage": true,
  "vehicle_zone": "4",
  "zone_description": "rear_left_quarter",
  "zone_area": "posterior",
  
  "specific_part": "Rear left corner panel near bumper junction",
  "text_description": "Vehicle zone: rear_left_quarter (posterior area). Affected part: Rear left corner panel near bumper junction. Damage types: Surface scratch (minor abrasion, 2 instances), Dent (metal deformation, 1 instance). Spatial pattern: Scratches clustered around dent, suggesting single impact event.",
  
  "damage_types": ["surface_scratch", "dent"],
  "damage_count": 3,
  "damage_descriptions": {
    "surface_scratch": "Minor abrasion, 2 instances",
    "dent": "Metal deformation, 1 instance"
  },
  "spatial_pattern": "Scratches clustered around dent, suggesting single impact event",
  
  "crop_type": "clustered",
  "crop_size": [448, 448],
  
  "embedding_index": 42,
  "embedding_model": "hybrid_dinov3_sbert_50_50",
  "embedding_dim": 1408,
  "embedding_norm": 1.0000,
  "visual_emb_norm": 1.0000,
  "text_emb_norm": 1.0000
}
```

### Metadata para Crop Sin DaÃ±o

```json
{
  "crop_id": "zona1_ok_2_3_1554373063646_zona_6_grid_0_1",
  "crop_path": "data/processed/crops/balanced_dataset/clean/zona1_ok_..._grid_0_1.jpg",
  "source_image": "zona1_ok_2_3_1554373063646_zona_6_imageDANO_original.jpg",
  
  "has_damage": false,
  "vehicle_zone": "6",
  "zone_description": "rear_right_quarter",
  "zone_area": "posterior",
  
  "specific_part": "Right rear quarter panel",
  "text_description": "Vehicle zone: rear_right_quarter (posterior area). Inspected part: Right rear quarter panel. Surface condition: Clean paint, no scratches or dents detected. Panel integrity: Normal alignment, intact surface.",
  
  "damage_types": [],
  "damage_count": 0,
  
  "crop_type": "grid",
  "crop_grid_position": [0, 1],
  "crop_size": [448, 448],
  "crop_coverage_area": 0.11,
  
  "embedding_index": 1234,
  "embedding_model": "hybrid_dinov3_sbert_50_50",
  "embedding_dim": 1408,
  "embedding_norm": 1.0000,
  "visual_emb_norm": 1.0000,
  "text_emb_norm": 1.0000
}
```

---

## âš™ï¸ ConfiguraciÃ³n y ParÃ¡metros

### ParÃ¡metros Clave

| ParÃ¡metro | Valor | JustificaciÃ³n |
|-----------|-------|---------------|
| Crop Size | 448Ã—448 | Ã“ptimo para DINOv3-ViT-L/16 |
| Grid Overlap | 25% | Balance cobertura/eficiencia |
| Min Vehicle Ratio | 70% | Minimizar fondo innecesario |
| Visual Weight | 0.5 (50%) | Equilibrio modalidades |
| Text Weight | 0.5 (50%) | Equilibrio modalidades |
| Embedding Dim | 1408 | 1024 (visual) + 384 (text) |
| FAISS Index | IndexHNSWFlat | Ã“ptimo para <10K vectores |
| HNSW M | 32 | Conectividad Ã³ptima |
| efConstruction | 200 | Calidad construcciÃ³n |
| efSearch | 64 | Calidad bÃºsqueda |

### ConfiguraciÃ³n de Crops

```yaml
# config/crop_strategy_config.yaml

roi_crops:
  target_size: [448, 448]
  maintain_aspect: true

grid_crops:
  crop_size: 448
  overlap: 0.25
  min_vehicle_ratio: 0.70

vehicle_detection:
  model: yolov8n
  confidence_threshold: 0.5
  bbox_expansion: 0.15  # 15% de margen
```

### ConfiguraciÃ³n de Embeddings

```yaml
# config/embedding_config.yaml

multimodal:
  visual_weight: 0.5
  text_weight: 0.5
  normalize: true

visual:
  model: dinov3-vitl16
  dimension: 1024
  use_bfloat16: true

textual:
  model: all-MiniLM-L6-v2
  dimension: 384
  normalize: true
```

---

## ğŸ“ˆ Resultados Esperados

### EstadÃ­sticas del Pipeline

| Fase | Input | Output | Tiempo |
|------|-------|--------|--------|
| Fase 1 | 552 imÃ¡genes | ~2,500 crops | 15-20 min |
| Fase 2 | 2,500 crops | Contextos enriquecidos | 30-40 min |
| Fase 3 | 2,500 crops | Embeddings 1408d | 20-25 min |
| Fase 4 | 2,500 embeddings | Ãndice FAISS | 2-3 min |
| Fase 5 | Ãndice FAISS | ValidaciÃ³n | 5-10 min |
| **TOTAL** | - | - | **~1.5 horas** |

### MÃ©tricas de Calidad

#### Crops
- âœ… ~850 crops damaged (clusterizados)
- âœ… ~1,500-2,000 crops clean (grid)
- âœ… Total: ~2,500 crops
- âœ… Todos 448Ã—448 (o proporcionalmente escalados)
- âœ… Crops clean con >70% Ã¡rea del vehÃ­culo

#### Contextos Textuales
- âœ… 100% de crops con text_description
- âœ… Longitud promedio: 150-180 caracteres
- âœ… Damaged: zona + parte + tipos + relaciÃ³n espacial
- âœ… Clean: zona + parte + condiciÃ³n superficie

#### Embeddings
- âœ… Shape: (2500, 1408)
- âœ… Dtype: float32
- âœ… NormalizaciÃ³n L2: norma ~1.0
- âœ… Sin NaN o Inf
- âœ… Balance 50/50 (visual/text)

#### Ãndice FAISS
- âœ… Tipo: IndexHNSWFlat
- âœ… Vectores: 2,500
- âœ… DimensiÃ³n: 1408
- âœ… TamaÃ±o: ~20-25 MB
- âœ… Latencia bÃºsqueda: <50ms
- âœ… Recall@5: >80% (esperado)

### ComparaciÃ³n con Versiones Anteriores

| Aspecto | v1.0 (Crops solos) | v2.0 (Hybrid Fullimages) | v3.0 (Balanced Hybrid) |
|---------|-------------------|-------------------------|----------------------|
| Dataset | 815 damaged | 815 full images | 552 balanced (50/50) |
| Crops | 850 clustered | 0 (full images) | ~2,500 (mixed) |
| Embedding | DINOv3 only | Hybrid 60/40 | Hybrid 50/50 |
| Contexto | BÃ¡sico | Zona + descripciÃ³n | Rico (parte + daÃ±os + espacial) |
| Ãndice | 850 vectores | 815 vectores | ~2,500 vectores |
| Filtros | Tipo + zona | Zona + has_damage | Zona + has_damage + tipo |
| Recall@5 | ~60% | ~45% | >70% (esperado) |

---

## ğŸš€ PrÃ³ximos Pasos

### ImplementaciÃ³n Inmediata

1. **Implementar Fase 1**:
   - Crear VehicleDetector
   - Crear GridCropGenerator
   - Modificar ClusteredCropGenerator
   - Script phase1_generate_crops.py

2. **Implementar Fase 2**:
   - Crear DamageContextualizer
   - Integrar DINOv3 para partes especÃ­ficas
   - Script phase2_generate_contexts.py

3. **Implementar Fase 3**:
   - Modificar MultimodalEmbedder (pesos 50/50)
   - Script phase3_generate_hybrid_embeddings.py

4. **Implementar Fase 4**:
   - Crear UnifiedFAISSBuilder
   - Script phase4_build_unified_faiss_index.py

5. **Implementar Fase 5**:
   - Crear UnifiedRetriever con filtros
   - Script phase5_validate_retrieval.py

### Mejoras Futuras (Post-MVP)

#### Corto Plazo
- â˜ Aumentar tamaÃ±o de crops a 512Ã—512 o 640Ã—640
- â˜ Experimentar con pesos dinÃ¡micos (adaptative fusion)
- â˜ Agregar mÃ¡s filtros (severidad, mÃºltiples tipos)
- â˜ Implementar re-ranking con cross-attention

#### Medio Plazo
- â˜ Fine-tuning de DINOv3 en dataset vehicular
- â˜ Implementar hard negative mining
- â˜ Agregar augmentations durante generaciÃ³n de crops
- â˜ Explorar IndexIVFPQ para datasets mÃ¡s grandes

#### Largo Plazo
- â˜ Multi-modal fusion con attention weights
- â˜ Integrar segmentaciÃ³n automÃ¡tica (SAM)
- â˜ Sistema de active learning para mejorar contextos
- â˜ Deploy en producciÃ³n con API REST

---

## ğŸ“š Referencias

### Papers CientÃ­ficos

1. **DINOv3**: "DINOv3: A SELF-SUPERVISED VISION TRANSFORMER MODEL" (2023)
   - https://arxiv.org/abs/2304.07193

2. **HNSW**: "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs" (2018)
   - https://arxiv.org/abs/1603.09320

3. **Multimodal Embeddings**: "CLIP: Learning Transferable Visual Models From Natural Language Supervision" (2021)
   - https://arxiv.org/abs/2103.00020

4. **RAG**: "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (2020)
   - https://arxiv.org/abs/2005.11401

### Herramientas y LibrerÃ­as

- **FAISS**: https://github.com/facebookresearch/faiss
- **Sentence-Transformers**: https://www.sbert.net/
- **YOLOv8**: https://docs.ultralytics.com/
- **Transformers (Hugging Face)**: https://huggingface.co/docs/transformers

---

## ğŸ“ Changelog

### v3.0 (Balanced Hybrid - Current)
- âœ¨ Dataset balanceado 50/50 (ko + ok)
- âœ¨ Grid crops para imÃ¡genes limpias
- âœ¨ Contexto enriquecido con parte especÃ­fica
- âœ¨ Embeddings hÃ­bridos 50/50
- âœ¨ Ãndice unificado con filtros avanzados
- ğŸ”§ Eliminado padding adaptativo en crops damaged

### v2.0 (Hybrid Fullimages)
- âœ¨ Embeddings hÃ­bridos 60/40
- âœ¨ Full images con metadata enriquecida
- âœ¨ Contexto textual bÃ¡sico

### v1.0 (Crops Only)
- âœ¨ Crops clusterizados
- âœ¨ Embeddings DINOv3 puro
- âœ¨ Ãndice FAISS bÃ¡sico

---

## ğŸ¤ ContribuciÃ³n

Este documento describe la arquitectura implementada. Para modificaciones o mejoras:

1. Revisar la secciÃ³n **MÃ³dulos del Sistema**
2. Actualizar scripts correspondientes en `scripts/phase*.py`
3. Documentar cambios en este README
4. Validar con Fase 5 antes de integrar

---

**Ãšltima actualizaciÃ³n**: Noviembre 2024  
**VersiÃ³n del documento**: 3.0  
**Estado**: ImplementaciÃ³n en progreso